// uwpspatialsoundtest.cpp : This file contains the 'main' function. Program execution begins and ends there.
// Most (if not all) of these are from https://learn.microsoft.com/en-us/windows/win32/coreaudio/render-spatial-sound-using-spatial-audio-objects

#include <iostream>
#include <fstream>
#include <random>
#include <stdlib.h>
#include <locale.h>

#include <windows.foundation.h>
#include <windowsnumerics.h>
#include <wrl/wrappers/corewrappers.h>
#include <wrl/client.h>
#include <SpatialAudioClient.h>
#include <mmdeviceapi.h>

// Audio object struct
struct Speaker3dObject {
    Microsoft::WRL::ComPtr<ISpatialAudioObject> audioObject;
    Windows::Foundation::Numerics::float3 position;
    float volume;
    UINT totalFrameCount;
    UINT currFrameIndex;   // Since chunks of audio are written to buffer
};


// Something the demo uses to write sine PCM waves to buffer
//void WriteToAudioObjectBuffer(FLOAT* buffer, UINT frameCount, FLOAT frequency, UINT samplingRate)
//{
//    const double PI = 4 * atan2(1.0, 1.0);
//    static double _radPhase = 0.0;
//
//    double step = 2 * PI * frequency / samplingRate;
//
//    for (UINT i = 0; i < frameCount; i++)
//    {
//        double sample = sin(_radPhase);
//
//        buffer[i] = FLOAT(sample);
//
//        _radPhase += step; // next frame phase
//
//        if (_radPhase >= 2 * PI)
//        {
//            _radPhase -= 2 * PI;
//        }
//    }
//}

// Writes frameCount samples from PCM sample vector to buffer
UINT WriteToAudioObjectBuffer(FLOAT* buffer, UINT frameCount, const std::vector<float> &data, UINT &pos) {
    UINT writeLen = min(frameCount, static_cast<UINT>(max(0, data.size() - pos)));
    if(writeLen > 0) {
        memcpy(buffer, data.data() + pos, sizeof(float) * writeLen);
		pos += writeLen;
    }
    if(writeLen < frameCount) {
		memset(buffer + writeLen, 0, sizeof(float) * (frameCount - writeLen)); // Zero-fill remainder
    }
    return writeLen; // Required for ISpatialAudioObjectBase::SetEndOfStream
}


// These 24-bit WAV loading utility functions are generated by Copilot.
// TODO: Change them to dynamically load other bit depths, maybe use avlibcodec (?)

// Convert signed 24-bit little-endian (3 bytes) to int32 with sign extension
static inline int32_t Int24ToInt32(const uint8_t bytes[3])
{
    int32_t val = (bytes[0]) | (bytes[1] << 8) | (bytes[2] << 16);
    // sign extend if negative (bit 23 set)
    if(val & 0x00800000) {
        val |= 0xFF000000;
    }
    return val;
}

// Load a mono 24-bit PCM WAV file and convert to float32 samples in range [-1,1).
// Returns true on success and fills outSamples and outSampleRate.
bool LoadWav24ToFloat(const std::wstring& path, std::vector<float>& outSamples, UINT& outSampleRate)
{
    std::ifstream ifs(path, std::ios::binary);
    if(!ifs) return false;

    // Read RIFF header
    char riff[4];
    uint32_t riffChunkSize = 0;
    char wave[4];
    ifs.read(riff, 4);
    ifs.read(reinterpret_cast<char*>(&riffChunkSize), 4);
    ifs.read(wave, 4);
    if(std::strncmp(riff, "RIFF", 4) != 0 || std::strncmp(wave, "WAVE", 4) != 0)
        return false;

    // Parse chunks
    uint16_t audioFormat = 0;
    uint16_t numChannels = 0;
    uint32_t sampleRate = 0;
    uint16_t bitsPerSample = 0;
    std::vector<uint8_t> dataBytes;

    while(ifs && !ifs.eof()) {
        char chunkId[4];
        uint32_t chunkSize = 0;
        ifs.read(chunkId, 4);
        if (!ifs) break;
        ifs.read(reinterpret_cast<char*>(&chunkSize), 4);
        if (!ifs) break;

        std::streampos nextChunk = ifs.tellg();
        nextChunk += static_cast<std::streamoff>(chunkSize);

        if(std::strncmp(chunkId, "fmt ", 4) == 0) {
            // Read format chunk (at least 16 bytes)
            if (chunkSize < 16) return false;
            ifs.read(reinterpret_cast<char*>(&audioFormat), sizeof(audioFormat));
            ifs.read(reinterpret_cast<char*>(&numChannels), sizeof(numChannels));
            ifs.read(reinterpret_cast<char*>(&sampleRate), sizeof(sampleRate));
            uint32_t byteRate = 0;
            uint16_t blockAlign = 0;
            ifs.read(reinterpret_cast<char*>(&byteRate), sizeof(byteRate));
            ifs.read(reinterpret_cast<char*>(&blockAlign), sizeof(blockAlign));
            ifs.read(reinterpret_cast<char*>(&bitsPerSample), sizeof(bitsPerSample));
            // skip any extra fmt bytes
        }
        else if(std::strncmp(chunkId, "data", 4) == 0) {
            dataBytes.resize(chunkSize);
            ifs.read(reinterpret_cast<char*>(dataBytes.data()), chunkSize);
        }
        // advance to next chunk (handle odd chunk sizes)
        ifs.seekg(nextChunk);
    }

    if(audioFormat != 1) return false; // expect PCM (1)
    if(numChannels != 1) return false;  // expect mono
    if(bitsPerSample != 24) return false; // expect 24-bit

    // Convert 3-byte samples to float
    const size_t bytesPerSample = 3;
    size_t sampleCount = dataBytes.size() / bytesPerSample;
    outSamples.resize(sampleCount);
    const float denom = 8388608.0f; // 2^23
    for(size_t i = 0; i < sampleCount; ++i) {
        const uint8_t* b = &dataBytes[i * bytesPerSample];
        int32_t s = Int24ToInt32(b);
        outSamples[i] = static_cast<float>(s) / denom;
    }

    outSampleRate = sampleRate;
    return true;
}

// Linear resampler from inRate -> outRate.
// Simple, fast, acceptable for small test/demo. Use a higher-quality library for production.
void ResampleLinear(const std::vector<float>& in, UINT inRate, UINT outRate, std::vector<float>& out)
{
    if (inRate == outRate) {
        out = in;
        return;
    }
    if (in.empty()) {
        out.clear();
        return;
    }

    double ratio = static_cast<double>(outRate) / static_cast<double>(inRate);
    size_t outLen = static_cast<size_t>(std::floor(in.size() * ratio + 0.5));
    out.resize(outLen);

    for (size_t j = 0; j < outLen; ++j) {
        double srcPos = static_cast<double>(j) / ratio;
        size_t i0 = static_cast<size_t>(std::floor(srcPos));
        double frac = srcPos - static_cast<double>(i0);
        float s0 = in[min(i0, in.size() - 1)];
        float s1 = in[min(i0 + 1, in.size() - 1)];
        out[j] = static_cast<float>((1.0 - frac) * s0 + frac * s1);
    }
}



int main(int argc, char* argv[]) {
    // Getting WAV file (test file uses 24-bit, mono, 44.100kHz at the moment)
    if(argc < 2) {
		std::cerr << "Please provide a path to a mono 24-bit WAV file as an argument." << std::endl;
        return 1;
    }
	
	std::setlocale(LC_ALL, ""); // Default locale
	size_t requiredSize = strlen(argv[1]) + 1;
	wchar_t* pwc = new wchar_t[requiredSize];
    size_t outWSize;
	mbstowcs_s(&outWSize, pwc, requiredSize, argv[1], requiredSize - 1);
    std::wstring wavPath(pwc);
    delete[] pwc;

    // Load WAV samples into vector<float>
	std::vector<float> wavSamples;
	UINT wavSampleRate;
	if(!LoadWav24ToFloat(wavPath, wavSamples, wavSampleRate)) {
        std::cerr << "Failed to load WAV" << std::endl;
        return 1;
	}

    // Resample to 48kHz
    const UINT targetRate = 48000;
    if(wavSampleRate != targetRate) {
        std::vector<float> resampled;
        ResampleLinear(wavSamples, wavSampleRate, targetRate, resampled);
        wavSamples.swap(resampled);
        wavSampleRate = targetRate;
    }


    // This is where we get the audio device
    HRESULT hr = CoInitialize(nullptr);
    Microsoft::WRL::ComPtr<IMMDeviceEnumerator> deviceEnum;
    Microsoft::WRL::ComPtr<IMMDevice> defaultDevice;

    hr = CoCreateInstance(__uuidof(MMDeviceEnumerator), nullptr, CLSCTX_ALL, __uuidof(IMMDeviceEnumerator), (void**)&deviceEnum);
    hr = deviceEnum->GetDefaultAudioEndpoint(EDataFlow::eRender, eMultimedia, &defaultDevice);



    // This is where the audio format is specified (32-bit, mono, 48kHz)
    WAVEFORMATEX format;
    format.wFormatTag = WAVE_FORMAT_IEEE_FLOAT;
    format.wBitsPerSample = 32;
    format.nChannels = 1;
    format.nSamplesPerSec = wavSampleRate;
    format.nBlockAlign = (format.wBitsPerSample >> 3) * format.nChannels;
    format.nAvgBytesPerSec = format.nBlockAlign * format.nSamplesPerSec;
    format.cbSize = 0;



    // Activate ISpatialAudioClient on the desired audio-device 
    Microsoft::WRL::ComPtr<ISpatialAudioClient> spatialAudioClient;
    hr = defaultDevice->Activate(__uuidof(ISpatialAudioClient), CLSCTX_INPROC_SERVER, nullptr, (void**)&spatialAudioClient);

    hr = spatialAudioClient->IsAudioObjectFormatSupported(&format);
    if(FAILED(hr)) {
		std::cerr << "Audio object format not supported by spatial audio client." << std::endl;
        return 1;
    }

    // Create the event that will be used to signal the client for more data
    HANDLE bufferCompletionEvent = CreateEvent(nullptr, FALSE, FALSE, nullptr);

    // 220 max dynamic objects for Windows Sonic UWP
    UINT32 maxDynamicObjectCount;
    hr = spatialAudioClient->GetMaxDynamicObjectCount(&maxDynamicObjectCount);

    if(maxDynamicObjectCount == 0) {
        // Dynamic objects are unsupported
        return 1;
    }

    // Set the maximum number of dynamic audio objects that will be used
    SpatialAudioObjectRenderStreamActivationParams streamParams;
    streamParams.ObjectFormat = &format;
    streamParams.StaticObjectTypeMask = AudioObjectType_None;
    streamParams.MinDynamicObjectCount = 0;
    streamParams.MaxDynamicObjectCount = min(maxDynamicObjectCount, 4);
    streamParams.Category = AudioCategory_GameEffects;
    streamParams.EventHandle = bufferCompletionEvent;
    streamParams.NotifyObject = nullptr;

    PROPVARIANT pv;
    PropVariantInit(&pv);
    pv.vt = VT_BLOB;
    pv.blob.cbSize = sizeof(streamParams);
    pv.blob.pBlobData = (BYTE*)&streamParams;

    Microsoft::WRL::ComPtr<ISpatialAudioObjectRenderStream> spatialAudioStream;
    hr = spatialAudioClient->ActivateSpatialAudioStream(&pv, __uuidof(spatialAudioStream), (void**)&spatialAudioStream);

    // Start streaming / rendering 
    hr = spatialAudioStream->Start();
    Microsoft::WRL::ComPtr<ISpatialAudioObject> audioObject;
    hr = spatialAudioStream->ActivateSpatialAudioObject(AudioObjectType::AudioObjectType_Dynamic, &audioObject);

    // Initializing sound object
	Speaker3dObject leftSpeakerObj;
	leftSpeakerObj.audioObject = audioObject;
	leftSpeakerObj.position = Windows::Foundation::Numerics::float3(-1.0f, 0.0f, 0.0f); // Left by 1 meter (I think)
	leftSpeakerObj.volume = 1.0f;
    leftSpeakerObj.totalFrameCount = static_cast<UINT>(wavSamples.size());
    leftSpeakerObj.currFrameIndex = 0;

	bool streaming = true;
    while(streaming) {
        // Wait for a signal from the audio-engine to start the next processing pass
        if (WaitForSingleObject(bufferCompletionEvent, 100) != WAIT_OBJECT_0) {
            break;
        }

        UINT32 availableDynamicObjectCount;
		UINT32 frameCount;
		hr = spatialAudioStream->BeginUpdatingAudioObjects(&availableDynamicObjectCount, &frameCount);

        BYTE* buffer;
		UINT32 bufferLength;

		hr = leftSpeakerObj.audioObject->GetBuffer(&buffer, &bufferLength);

        // Write audio to available frames
        UINT writeLen = WriteToAudioObjectBuffer(reinterpret_cast<float*>(buffer), frameCount, wavSamples, leftSpeakerObj.currFrameIndex);
        leftSpeakerObj.audioObject->SetPosition(leftSpeakerObj.position.x, leftSpeakerObj.position.y, leftSpeakerObj.position.z);
        leftSpeakerObj.audioObject->SetVolume(leftSpeakerObj.volume);

        // End of data
        if (leftSpeakerObj.currFrameIndex >= leftSpeakerObj.totalFrameCount) {
            hr = leftSpeakerObj.audioObject->SetEndOfStream(writeLen);
            leftSpeakerObj.audioObject = nullptr;
            leftSpeakerObj.totalFrameCount = 0;
            streaming = false;
        }

        hr = spatialAudioStream->EndUpdatingAudioObjects();
    }

    
	// From Microsoft article, spawns a bunch of sine waves around listener
    //// Used for generating a vector of randomized My3DObject structs
    //std::vector<My3dObject> objectVector;
    //std::default_random_engine gen;
    //std::uniform_real_distribution<> pos_dist(-25, 25); // uniform distribution for random position
    //std::uniform_real_distribution<> vel_dist(-1, 1); // uniform distribution for random velocity
    //std::uniform_real_distribution<> vol_dist(0.5, 1.0); // uniform distribution for random volume
    //std::uniform_real_distribution<> pitch_dist(40, 400); // uniform distribution for random pitch
    //int spawnCounter = 0;
    // 
    //do
    //{
    //    // Wait for a signal from the audio-engine to start the next processing pass
    //    if (WaitForSingleObject(bufferCompletionEvent, 100) != WAIT_OBJECT_0)
    //    {
    //        break;
    //    }

    //    UINT32 availableDynamicObjectCount;
    //    UINT32 frameCount;

    //    // Begin the process of sending object data and metadata
    //    // Get the number of active objects that can be used to send object-data
    //    // Get the frame count that each buffer will be filled with 
    //    hr = spatialAudioStream->BeginUpdatingAudioObjects(&availableDynamicObjectCount, &frameCount);

    //    BYTE* buffer;
    //    UINT32 bufferLength;

    //    // Spawn a new dynamic audio object every 200 iterations
    //    if (spawnCounter % 200 == 0 && spawnCounter < 1000)
    //    {
    //        // Activate a new dynamic audio object
    //        Microsoft::WRL::ComPtr<ISpatialAudioObject> audioObject;
    //        hr = spatialAudioStream->ActivateSpatialAudioObject(AudioObjectType::AudioObjectType_Dynamic, &audioObject);

    //        // If SPTLAUDCLNT_E_NO_MORE_OBJECTS is returned, there are no more available objects
    //        if (SUCCEEDED(hr))
    //        {
    //            // Init new struct with the new audio object.
    //            My3dObject obj = {
    //                audioObject,
    //                Windows::Foundation::Numerics::float3(static_cast<float>(pos_dist(gen)), static_cast<float>(pos_dist(gen)), static_cast<float>(pos_dist(gen))),
    //                Windows::Foundation::Numerics::float3(static_cast<float>(vel_dist(gen)), static_cast<float>(vel_dist(gen)), static_cast<float>(vel_dist(gen))),
    //                static_cast<float>(static_cast<float>(vol_dist(gen))),
    //                static_cast<float>(static_cast<float>(pitch_dist(gen))),
    //                format.nSamplesPerSec * 5 // 5 seconds of audio samples
    //            };

    //            objectVector.insert(objectVector.begin(), obj);
    //        }
    //    }
    //    spawnCounter++;

    //    // Loop through all dynamic audio objects
    //    std::vector<My3dObject>::iterator it = objectVector.begin();
    //    while (it != objectVector.end())
    //    {
    //        it->audioObject->GetBuffer(&buffer, &bufferLength);

    //        if (it->totalFrameCount >= frameCount)
    //        {
    //            // Write audio data to the buffer
    //            WriteToAudioObjectBuffer(reinterpret_cast<float*>(buffer), frameCount, it->frequency, format.nSamplesPerSec);

    //            // Update the position and volume of the audio object
    //            it->audioObject->SetPosition(it->position.x, it->position.y, it->position.z);
    //            it->position += it->velocity;
    //            it->audioObject->SetVolume(it->volume);

    //            it->totalFrameCount -= frameCount;

    //            ++it;
    //        }
    //        else
    //        {
    //            // If the audio object reaches its lifetime, set EndOfStream and release the object

    //            // Write audio data to the buffer
    //            WriteToAudioObjectBuffer(reinterpret_cast<float*>(buffer), it->totalFrameCount, it->frequency, format.nSamplesPerSec);

    //            // Set end of stream for the last buffer 
    //            hr = it->audioObject->SetEndOfStream(it->totalFrameCount);

    //            it->audioObject = nullptr; // Release the object

    //            it->totalFrameCount = 0;

    //            it = objectVector.erase(it);
    //        }
    //    }

    //    // Let the audio-engine know that the object data are available for processing now
    //    hr = spatialAudioStream->EndUpdatingAudioObjects();
    //} while (objectVector.size() > 0);



    // Stop the stream 
    hr = spatialAudioStream->Stop();

    // We don't want to start again, so reset the stream to free it's resources.
    hr = spatialAudioStream->Reset();

    CloseHandle(bufferCompletionEvent);

    return 0;
}

// Run program: Ctrl + F5 or Debug > Start Without Debugging menu
// Debug program: F5 or Debug > Start Debugging menu

// Tips for Getting Started: 
//   1. Use the Solution Explorer window to add/manage files
//   2. Use the Team Explorer window to connect to source control
//   3. Use the Output window to see build output and other messages
//   4. Use the Error List window to view errors
//   5. Go to Project > Add New Item to create new code files, or Project > Add Existing Item to add existing code files to the project
//   6. In the future, to open this project again, go to File > Open > Project and select the .sln file
